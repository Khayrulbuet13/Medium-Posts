{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Interactive Linear Regression Learning Playbook\n",
    "\n",
    "Welcome to your comprehensive guide to understanding Linear Regression! This notebook will take you through the fundamental concepts with interactive visualizations and hands-on exercises.\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand what linear regression is and when to use it\n",
    "- Learn the mathematical foundation behind linear regression\n",
    "- Explore how different parameters affect the model\n",
    "- Practice with real datasets\n",
    "- Evaluate model performance\n",
    "\n",
    "## ğŸ“– Table of Contents\n",
    "\n",
    "1. [What is Linear Regression?](#section1)\n",
    "2. [Mathematical Foundation](#section2)\n",
    "3. [Simple Linear Regression - Interactive Demo](#section3)\n",
    "4. [Real Dataset Example - Student Scores](#section4)\n",
    "5. [Multiple Linear Regression](#section5)\n",
    "6. [Model Evaluation](#section6)\n",
    "7. [Practice Exercises](#section7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas matplotlib seaborn scikit-learn ipywidgets plotly\n",
    "!wget https://raw.githubusercontent.com/Khayrulbuet13/Medium-Posts/refs/heads/main/LinnearRegression/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Welcome to the Interactive Linear Regression Learning Playbook!\n",
      "ğŸš€ All libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Import our utility functions\n",
    "import utils\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ“š Welcome to the Interactive Linear Regression Learning Playbook!\")\n",
    "print(\"ğŸš€ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple student scores dataset saved successfully!\n",
      "student_scores dataset saved successfully!\n",
      "simple house price dataset saved successfully!\n",
      "house_price_dataset saved successfully!\n",
      "All csv files created successfully!\n"
     ]
    }
   ],
   "source": [
    "utils.create_simple_student_score_dataset(), utils.create_student_score_dataset()\n",
    "utils.create_simple_house_price_dataset(), utils.create_house_price_dataset()\n",
    "print(\"All csv files created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "## 1. ğŸ¤” What is Linear Regression?\n",
    "\n",
    "> **Oneâ€‘line intuition:** *Linear regression draws the simplest possible trendâ€‘line through your data by **adding up weighted pieces of the input**.*\n",
    "\n",
    "### Formal Definition\n",
    "\n",
    "Linear regression models the relationship between a **target** (dependent variable, $y$) and one or more **features** (independent variables, collected in a design matrix $X$) by learning coefficients $\\boldsymbol{\\beta}$ that appear **linearly** in the equation\n",
    "\n",
    "$$\n",
    "\\hat y = \\beta_0 + \\beta_1\\,f_1(X)\\; + \\; \\beta_2\\,f_2(X)\\; + \\;\\dots + \\beta_k\\,f_k(X).\n",
    "$$\n",
    "\n",
    "The functions $f_j(\\cdot)$ may be nonlinear transformations of the raw inputs (e.g. $X^2$, $\\log X$), yet the *parameters* $\\beta_j$ enter only as *additive, firstâ€‘power* termsâ€”this is what keeps the model \"linear\".\n",
    "\n",
    "### ğŸ¤“ Why â€œLinear in Parametersâ€ Matters\n",
    "\n",
    "* **ğŸ“ Straight line**: $Y=\\beta_0+\\beta_1X$\n",
    "* **ğŸŒ€ Curved but linear**: $Y=\\beta_0+\\beta_1X+\\beta_2X^2$\n",
    "* **ğŸ“‰ Log transform**: $Y=\\beta_0+\\beta_1\\log X$\n",
    "* **ğŸ”— Interaction**: $Y=\\beta_0+\\beta_1X_1+\\beta_2X_2X_3$\n",
    "\n",
    "If a coefficient is *wrapped inside* a nonlinear functionâ€”e.g. $Y = \\beta_0 + e^{\\beta_1 X}$â€”the model leaves the linearâ€‘regression family and becomes genuinely *nonlinear*.\n",
    "\n",
    "## ğŸ“˜ Key Concepts\n",
    "\n",
    "**Dependent variable (Y)**: What we want to predict\n",
    "\n",
    "**Independent variables (X)**: What we use to make predictions\n",
    "\n",
    "**Weights / Coefficients ($\\beta$)**: Learned parameters that quantify each feature's influence\n",
    "\n",
    "**Model linearity**: Linear in parametersâ€”even if relationship appears curved\n",
    "\n",
    "**Design matrix (X)**: Matrix containing all input features plus intercept column\n",
    "\n",
    "**Residuals ($\\varepsilon$)**: Differences between actual and predicted values\n",
    "\n",
    "### When to Reach for Linear Regression\n",
    "\n",
    "* You believe the (possibly transformed) features relate approximately linearly to the target.\n",
    "* You need an **interpretable** baseline before trying fancier models.\n",
    "* The target is **continuous** and errors are roughly symmetrical.\n",
    "* You want a quick yardâ€‘stick: linear models train instantly and provide a benchmark for MSE / $R^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='section2'></a>\n",
    "\n",
    "## 2. ğŸ§® Mathematical Foundation\n",
    "\n",
    "### 2.1  Model in Vector / Matrix Form\n",
    "\n",
    "Given\n",
    "\n",
    "* Design matrix $X\\in\\mathbb{R}^{n\\times (k+1)}$ (first columnÂ =Â 1â€™s for the intercept)\n",
    "* Parameter vector $\\boldsymbol{\\beta}\\in\\mathbb{R}^{k+1}$\n",
    "* Target vector $\\mathbf{y}\\in\\mathbb{R}^{n}$\n",
    "\n",
    "we write\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = X\\,\\boldsymbol{\\beta}, \\qquad \\mathbf{y}=\\hat{\\mathbf{y}}+\\boldsymbol{\\varepsilon}.\n",
    "$$\n",
    "\n",
    "### 2.2  Objective Function (Ordinary Least Squares)\n",
    "\n",
    "The coefficients are chosen to **minimise** the Mean Squared Error (MSE):\n",
    "\n",
    "$$\n",
    "J(\\boldsymbol{\\beta})\n",
    "= \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat y_i)^2\n",
    "= \\frac{1}{n}\\lVert\\mathbf{y}-X\\boldsymbol{\\beta}\\rVert_2^{\\,2}.\n",
    "$$\n",
    "\n",
    "### 2.3  Closedâ€‘form Solution (Normal Equation)\n",
    "\n",
    "When $X^TX$ is invertible,\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}\\;=\\;(X^T X)^{-1}X^T\\mathbf{y}.\n",
    "$$\n",
    "\n",
    "This gives the exact OLS solution in a single matrix step.\n",
    "\n",
    "### 2.4  Gradientâ€‘descent Alternative\n",
    "\n",
    "For huge datasets or streaming contexts we iterate\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\beta}\\leftarrow\\boldsymbol{\\beta} - \\eta \\frac{2}{n} X^T(X\\boldsymbol{\\beta}-\\mathbf{y}),\n",
    "$$\n",
    "\n",
    "with learningâ€‘rate $\\eta$.\n",
    "\n",
    "### 2.5  Quality Metrics\n",
    "\n",
    "| ğŸ“ Metric | ğŸ“ Formula                                    | ğŸ“£ Meaning         |\n",
    "| --------- | --------------------------------------------- | ------------------ |\n",
    "| ğŸ¯ $R^2$  | $1-\\frac{\\sum(y-\\hat y)^2}{\\sum(y-\\bar y)^2}$ | Variance explained |\n",
    "| ğŸ§® MSE    | $\\frac{1}{n}\\sum(y-\\hat y)^2$                 | Avg. squared error |\n",
    "| ğŸ“‰ MAE    | $\\frac{1}{n}\\sum\\|y-\\hat y\\|$                 | Avg. absolute error |\n",
    "\n",
    "### 2.6  Classical Assumptions (OLS)\n",
    "\n",
    "1. **Linearity** in parameters\n",
    "2. **Independence** of errors\n",
    "3. **Homoscedasticity** (constant error variance)\n",
    "4. **No perfect multicollinearity** among features\n",
    "5. **Normality** of errors (for inference)\n",
    "\n",
    "Violating these does *not* break prediction, but it affects reliability of confidence intervals and hypothesis tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "## 3. ğŸ® Simple Linear Regression - Interactive Demo\n",
    "\n",
    "Let's start with a simple example to understand how linear regression works!\n",
    "Move sliders to adjust slope and intercept independently! to minimize the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b628ccacb29548e6a41a0e6b9eb7d2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1 style=\"text-align: center; font-family: Arial, sans-serif; color: #2c3e50; margâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('simple_student_scores.csv')\n",
    "\n",
    "# Create an interactive regression demo using only Study_Hours as input\n",
    "slope_slider, intercept_slider = utils.create_interactive_regression_demo(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ OPTIMAL SOLUTION (using sklearn):\n",
      "   Optimal Slope: 9.343\n",
      "   Optimal Intercept: 4.808\n",
      "   Minimum MSE: 80.658\n",
      "   RÂ² Score: 0.823\n",
      "\n",
      "ğŸ’¡ How close were you to the optimal solution?\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the optimal solution looks like\n",
    "X_demo = df['Study_Hours'].values\n",
    "y_demo = df['Exam_Score'].values\n",
    "\n",
    "# Implement find_optimal_parameters directly here\n",
    "X_reshaped = X_demo.reshape(-1, 1)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_reshaped, y_demo)\n",
    "\n",
    "optimal_slope = model.coef_[0] if X_demo.ndim == 1 else model.coef_\n",
    "optimal_intercept = model.intercept_\n",
    "y_pred_optimal = model.predict(X_reshaped)\n",
    "optimal_mse = mean_squared_error(y_demo, y_pred_optimal)\n",
    "optimal_r2 = r2_score(y_demo, y_pred_optimal)\n",
    "\n",
    "print(\"ğŸ¯ OPTIMAL SOLUTION (using sklearn):\")\n",
    "print(f\"   Optimal Slope: {optimal_slope:.3f}\")\n",
    "print(f\"   Optimal Intercept: {optimal_intercept:.3f}\")\n",
    "print(f\"   Minimum MSE: {optimal_mse:.3f}\")\n",
    "print(f\"   RÂ² Score: {optimal_r2:.3f}\")\n",
    "print(\"\\nğŸ’¡ How close were you to the optimal solution?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "## 4. ğŸ“Š Predict Exam Score with the model we built\n",
    "You can hover over the interactive window to see what should be the exam score from given study hours, or we can use the linear regression model we just built to predict the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Example Predictions:\n",
      "   1 hours â†’ 14.2 points\n",
      "   3 hours â†’ 32.8 points\n",
      "   5 hours â†’ 51.5 points\n",
      "   7 hours â†’ 70.2 points\n",
      "   9 hours â†’ 88.9 points\n"
     ]
    }
   ],
   "source": [
    "Study_hours = [1, 3, 5, 7, 9]\n",
    "# Example predictions\n",
    "print(f\"\\nğŸ“Š Example Predictions:\")\n",
    "for hours in Study_hours:\n",
    "             score = model.predict([[hours]])[0]\n",
    "             print(f\"   {hours} hours â†’ {score:.1f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "\n",
    "## 5. ğŸ”¢ Multiple Linear Regression\n",
    "\n",
    "Now let's explore multiple linear regression with more features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Multiple Linear Regression Dataset\n",
      "Dataset shape: (200, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Study_Hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sleep_Hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Previous_Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Attendance_Percent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Exam_Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3aabfd52-e1c7-4826-981e-2aa60cf34b0a",
       "rows": [
        [
         "0",
         "4.370861069626263",
         "7.852189876925727",
         "45.67181278597629",
         "66.75740252288658",
         "83.7719203740052"
        ],
        [
         "1",
         "9.556428757689243",
         "4.504839789970293",
         "89.64040986737616",
         "71.14361356127834",
         "100.0"
        ],
        [
         "2",
         "7.587945476302646",
         "4.969772284567682",
         "67.78888048463214",
         "67.08041937106987",
         "100.0"
        ],
        [
         "3",
         "6.387926357773329",
         "9.391325131162477",
         "85.4551606359258",
         "63.548101350282224",
         "100.0"
        ],
        [
         "4",
         "2.404167763981929",
         "7.638574357957539",
         "57.602728056683645",
         "64.82543484402403",
         "82.7223293467774"
        ],
        [
         "5",
         "2.403950683025824",
         "4.055182309699778",
         "89.25377756729102",
         "78.43115072130902",
         "77.24825511589933"
        ],
        [
         "6",
         "1.5227525095137953",
         "4.608829257196192",
         "61.40609233037897",
         "68.2533487362317",
         "58.52415193556987"
        ],
        [
         "7",
         "8.795585311974417",
         "7.981010614648335",
         "40.59607083141641",
         "74.57079444192301",
         "100.0"
        ],
        [
         "8",
         "6.41003510568888",
         "4.030369503077312",
         "89.7960087030595",
         "80.13669083419427",
         "100.0"
        ],
        [
         "9",
         "7.372653200164409",
         "4.964848308504992",
         "45.02076722323734",
         "87.6157931451746",
         "100.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study_Hours</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Previous_Score</th>\n",
       "      <th>Attendance_Percent</th>\n",
       "      <th>Exam_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.370861</td>\n",
       "      <td>7.852190</td>\n",
       "      <td>45.671813</td>\n",
       "      <td>66.757403</td>\n",
       "      <td>83.771920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.556429</td>\n",
       "      <td>4.504840</td>\n",
       "      <td>89.640410</td>\n",
       "      <td>71.143614</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.587945</td>\n",
       "      <td>4.969772</td>\n",
       "      <td>67.788880</td>\n",
       "      <td>67.080419</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.387926</td>\n",
       "      <td>9.391325</td>\n",
       "      <td>85.455161</td>\n",
       "      <td>63.548101</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.404168</td>\n",
       "      <td>7.638574</td>\n",
       "      <td>57.602728</td>\n",
       "      <td>64.825435</td>\n",
       "      <td>82.722329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.403951</td>\n",
       "      <td>4.055182</td>\n",
       "      <td>89.253778</td>\n",
       "      <td>78.431151</td>\n",
       "      <td>77.248255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.522753</td>\n",
       "      <td>4.608829</td>\n",
       "      <td>61.406092</td>\n",
       "      <td>68.253349</td>\n",
       "      <td>58.524152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.795585</td>\n",
       "      <td>7.981011</td>\n",
       "      <td>40.596071</td>\n",
       "      <td>74.570794</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.410035</td>\n",
       "      <td>4.030370</td>\n",
       "      <td>89.796009</td>\n",
       "      <td>80.136691</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.372653</td>\n",
       "      <td>4.964848</td>\n",
       "      <td>45.020767</td>\n",
       "      <td>87.615793</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study_Hours  Sleep_Hours  Previous_Score  Attendance_Percent  Exam_Score\n",
       "0     4.370861     7.852190       45.671813           66.757403   83.771920\n",
       "1     9.556429     4.504840       89.640410           71.143614  100.000000\n",
       "2     7.587945     4.969772       67.788880           67.080419  100.000000\n",
       "3     6.387926     9.391325       85.455161           63.548101  100.000000\n",
       "4     2.404168     7.638574       57.602728           64.825435   82.722329\n",
       "5     2.403951     4.055182       89.253778           78.431151   77.248255\n",
       "6     1.522753     4.608829       61.406092           68.253349   58.524152\n",
       "7     8.795585     7.981011       40.596071           74.570794  100.000000\n",
       "8     6.410035     4.030370       89.796009           80.136691  100.000000\n",
       "9     7.372653     4.964848       45.020767           87.615793  100.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Description:\n",
      "This dataset contains simulated student data with the following features:\n",
      "- Study_Hours: Number of hours spent studying per week\n",
      "- Sleep_Hours: Average hours of sleep per night\n",
      "- Previous_Score: Previous exam score (out of 100)\n",
      "- Attendance_Percent: Class attendance percentage\n",
      "- Exam_Score: Current exam score (target variable, out of 100)\n"
     ]
    }
   ],
   "source": [
    "# Import the multiple linear regression dataset from CSV\n",
    "df_multi = pd.read_csv('student_scores.csv')\n",
    "\n",
    "print(\"ğŸ“Š Multiple Linear Regression Dataset\")\n",
    "print(f\"Dataset shape: {df_multi.shape}\")\n",
    "# print(\"\\nFirst 10 students:\")\n",
    "display(df_multi.head(10))\n",
    "\n",
    "print(\"\\nğŸ“ Description:\")\n",
    "print(\"This dataset contains simulated student data with the following features:\")\n",
    "print(\"- Study_Hours: Number of hours spent studying per week\")\n",
    "print(\"- Sleep_Hours: Average hours of sleep per night\")\n",
    "print(\"- Previous_Score: Previous exam score (out of 100)\")\n",
    "print(\"- Attendance_Percent: Class attendance percentage\")\n",
    "print(\"- Exam_Score: Current exam score (target variable, out of 100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Multiple Regression Model Parameters:\n",
      "   Study_Hours: 3.438\n",
      "   Sleep_Hours: 0.848\n",
      "   Previous_Score: 0.122\n",
      "   Attendance_Percent: 0.102\n",
      "   Intercept: 51.191\n",
      "\n",
      "ğŸ“ˆ Multiple Regression Performance:\n",
      "   Training RÂ² Score: 0.685\n",
      "   Test RÂ² Score: 0.691\n",
      "   Training MSE: 39.618\n",
      "   Test MSE: 47.660\n"
     ]
    }
   ],
   "source": [
    "# Build multiple linear regression model\n",
    "X_multi = df_multi[['Study_Hours', 'Sleep_Hours', 'Previous_Score', 'Attendance_Percent']]\n",
    "y_multi = df_multi['Exam_Score']\n",
    "\n",
    "# Split the data\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train the model\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_multi = model_multi.predict(X_train_multi)\n",
    "y_test_pred_multi = model_multi.predict(X_test_multi)\n",
    "\n",
    "print(f\"ğŸ¯ Multiple Regression Model Parameters:\")\n",
    "feature_names = ['Study_Hours', 'Sleep_Hours', 'Previous_Score', 'Attendance_Percent']\n",
    "for i, (feature, coef) in enumerate(zip(feature_names, model_multi.coef_)):\n",
    "    print(f\"   {feature}: {coef:.3f}\")\n",
    "print(f\"   Intercept: {model_multi.intercept_:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Multiple Regression Performance:\")\n",
    "print(f\"   Training RÂ² Score: {r2_score(y_train_multi, y_train_pred_multi):.3f}\")\n",
    "print(f\"   Test RÂ² Score: {r2_score(y_test_multi, y_test_pred_multi):.3f}\")\n",
    "print(f\"   Training MSE: {mean_squared_error(y_train_multi, y_train_pred_multi):.3f}\")\n",
    "print(f\"   Test MSE: {mean_squared_error(y_test_multi, y_test_pred_multi):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§® How Multiple Regression Predicts Exam Scores\n",
    "\n",
    "A **multiple linear regression** model predicts the target using this equation:\n",
    "\n",
    "### Multiple Linear Regression:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_4x_4 + \\epsilon$$\n",
    "\n",
    "Where:\n",
    "- $y$ = Exam Score (what we predict)\n",
    "- $\\beta_0$ = Intercept (baseline score)\n",
    "- $\\beta_1, \\beta_2, \\beta_3, \\beta_4$ = Coefficients for each feature\n",
    "- $x_1, x_2, x_3, x_4$ = Study Hours, Sleep Hours, Previous Score, Attendance\n",
    "- $\\epsilon$ = Error term\n",
    "\n",
    "**Example prediction with your model:**\n",
    "\n",
    "$$\\text{Exam Score} = 51.191 + 3.438 \\times \\text{Study Hours} + 0.848 \\times \\text{Sleep Hours} + 0.122 \\times \\text{Previous Score} + 0.102 \\times \\text{Attendance}$$\n",
    "\n",
    "### Cost Function (Mean Squared Error):\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "The goal is to find the best coefficients that **minimize** this cost function!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "\n",
    "## 6. ğŸ“ Model Evaluation\n",
    "\n",
    "Understanding how to evaluate your linear regression model is crucial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š COMPREHENSIVE MODEL EVALUATION\n",
      "==================================================\n",
      "\n",
      "ğŸ¯ Accuracy Metrics:\n",
      "   RÂ² Score: 0.6912\n",
      "   Adjusted RÂ²: 0.6560\n",
      "   Mean Squared Error (MSE): 47.6602\n",
      "   Root Mean Squared Error (RMSE): 6.9036\n",
      "   Mean Absolute Error (MAE): 5.9182\n",
      "\n",
      "ğŸ” Residual Analysis:\n",
      "   Residual Mean: -0.0780 (should be close to 0)\n",
      "   Residual Std Dev: 6.9032\n",
      "\n",
      "ğŸ’¡ Interpretation:\n",
      "   â€¢ RÂ² = 0.691 means 69.1% of variance is explained\n",
      "   â€¢ On average, predictions are off by 5.9 points (MAE)\n",
      "   â€¢ RMSE of 6.9 penalizes larger errors more than MAE\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive model evaluation using our utility function\n",
    "# Make predictions\n",
    "y_pred = model_multi.predict(X_test_multi)\n",
    "\n",
    "# Calculate various metrics\n",
    "r2 = r2_score(y_test_multi, y_pred)\n",
    "mse = mean_squared_error(y_test_multi, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_multi, y_pred)\n",
    "\n",
    "# Additional metrics\n",
    "n = len(y_test_multi)\n",
    "p = X_test_multi.shape[1]  # number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Mean and standard deviation of residuals\n",
    "residuals = y_test_multi - y_pred\n",
    "residual_mean = np.mean(residuals)\n",
    "residual_std = np.std(residuals)\n",
    "\n",
    "print(\"ğŸ“Š COMPREHENSIVE MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nğŸ¯ Accuracy Metrics:\")\n",
    "print(f\"   RÂ² Score: {r2:.4f}\")\n",
    "print(f\"   Adjusted RÂ²: {adjusted_r2:.4f}\")\n",
    "print(f\"   Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"   Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"   Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ” Residual Analysis:\")\n",
    "print(f\"   Residual Mean: {residual_mean:.4f} (should be close to 0)\")\n",
    "print(f\"   Residual Std Dev: {residual_std:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Interpretation:\")\n",
    "print(f\"   â€¢ RÂ² = {r2:.3f} means {r2*100:.1f}% of variance is explained\")\n",
    "print(f\"   â€¢ On average, predictions are off by {mae:.1f} points (MAE)\")\n",
    "print(f\"   â€¢ RMSE of {rmse:.1f} penalizes larger errors more than MAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ  Exercise 1: House Price Prediction Challenge\n",
    "\n",
    "Build a simple linear regression model to predict house prices and discover key factors that influence property values!\n",
    "\n",
    "### ğŸ“Š The Dataset\n",
    "\n",
    "The `simple_house_price_dataset.csv` dataset contains:\n",
    "- **Size_SqFt**: House size in square feet\n",
    "- **Location_Score**: Location quality (1-10 scale)\n",
    "- **Age_Years**: Age of the house\n",
    "- **Price_USD**: House price (target variable)\n",
    "\n",
    "### ğŸ¯ Your Mission\n",
    "\n",
    "Create a model that predicts house prices by:\n",
    "1. **Exploring** the data with quick statistics and visualizations\n",
    "2. **Building** a multiple linear regression model\n",
    "3. **Evaluating** performance with RÂ² and MSE\n",
    "4. **Interpreting** which factors impact price most\n",
    "5. **Predicting** prices for sample properties\n",
    "\n",
    "### ğŸ“ Steps to Complete\n",
    "\n",
    "1. **Explore**: Check statistics and correlations\n",
    "2. **Visualize**: Create scatter plots\n",
    "3. **Build**: Use multiple linear regression\n",
    "4. **Evaluate**: Calculate RÂ², MSE metrics\n",
    "5. **Interpret**: Analyze coefficients\n",
    "6. **Predict**: Test on sample houses\n",
    "\n",
    "Ready to become a real estate pricing expert? ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 - Solution Space\n",
    "# TODO: Add your code here to explore the house price dataset\n",
    "# 1. Create visualizations to understand the data\n",
    "# 2. Check correlations between features and price\n",
    "# 3. Build a linear regression model\n",
    "# 4. Evaluate the model performance\n",
    "\n",
    "# Example starter code (uncomment and complete):\n",
    "# print(\"ğŸ“Š Dataset Statistics:\")\n",
    "# display(df_houses.describe())\n",
    "\n",
    "# print(\"\\nğŸ”— Correlations:\")\n",
    "# print(df_houses.corr())\n",
    "\n",
    "# Your code here...\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ  Exercise 2: Advanced Feature Engineering\n",
    "\n",
    "Take your house price model to the next level by applying feature engineering techniques to improve prediction accuracy!\n",
    "\n",
    "### ğŸ“Š Enhanced Features\n",
    "\n",
    "Building on Exercise 1, explore additional features:\n",
    "- **Ceiling_Height_Ft**: Ceiling height in feet\n",
    "- **Garage_Size_Cars**: Garage capacity\n",
    "- **Distance_to_Metro_km**: Distance to nearest metro station\n",
    "\n",
    "### ğŸ”§ Engineering Techniques\n",
    "\n",
    "Try these transformations to boost model performance:\n",
    "- **Polynomial features**: `Size_SqFtÂ²`, `Age_YearsÂ³`\n",
    "- **Logarithmic features**: `log(Size_SqFt)`, `log(Distance_to_Metro_km + 1)`\n",
    "- **Interaction terms**: `Size_SqFt Ã— Location_Score`\n",
    "\n",
    "### ğŸ“ˆ Your Challenge\n",
    "\n",
    "1. Compare basic vs. engineered models\n",
    "2. Identify which features contribute most\n",
    "3. Visualize how feature engineering improves predictions\n",
    "\n",
    "Can you create a model that outperforms your Exercise 1 solution? ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - Solution Space\n",
    "# TODO: Add your code here to explore the house price dataset\n",
    "# 1. Create visualizations to understand the data\n",
    "# 2. Check correlations between features and price\n",
    "# 3. Build a linear regression model\n",
    "# 4. Evaluate the model performance\n",
    "\n",
    "# Example starter code (uncomment and complete):\n",
    "# print(\"ğŸ“Š Dataset Statistics:\")\n",
    "# display(df_houses.describe())\n",
    "\n",
    "# print(\"\\nğŸ”— Correlations:\")\n",
    "# print(df_houses.corr())\n",
    "\n",
    "# Your code here...\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You've completed the Interactive Linear Regression Learning Playbook! Here's what you've learned:\n",
    "\n",
    "### ğŸ“š Key Takeaways:\n",
    "1. **Linear Regression Fundamentals**: Understanding the mathematical foundation and when to use it\n",
    "2. **Interactive Learning**: How adjusting parameters affects model performance\n",
    "3. **Real-world Application**: Working with student scores dataset\n",
    "4. **Multiple Features**: Extending to multiple linear regression\n",
    "5. **Model Evaluation**: Comprehensive metrics and interpretation\n",
    "6. **Hands-on Practice**: Building your own models\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "- Try the practice exercises with different datasets\n",
    "- Experiment with feature engineering\n",
    "- Explore regularization techniques (Ridge, Lasso)\n",
    "- Learn about polynomial regression\n",
    "- Study advanced regression techniques\n",
    "\n",
    "### ğŸ“– Additional Resources:\n",
    "- [Scikit-learn Linear Regression Documentation](https://scikit-learn.org/stable/modules/linear_model.html)\n",
    "- [Student Scores Dataset](https://www.kaggle.com/datasets/shubham47/students-score-dataset-linear-regression)\n",
    "- [Multiple Linear Regression Dataset](https://www.kaggle.com/datasets/hussainnasirkhan/multiple-linear-regression-dataset)\n",
    "\n",
    "Happy learning! ğŸ“"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
