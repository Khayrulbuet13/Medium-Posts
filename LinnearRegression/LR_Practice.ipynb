{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Interactive Linear Regression Learning Playbook\n",
    "\n",
    "Welcome to your comprehensive guide to understanding Linear Regression! This notebook will take you through the fundamental concepts with interactive visualizations and hands-on exercises.\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand what linear regression is and when to use it\n",
    "- Learn the mathematical foundation behind linear regression\n",
    "- Explore how different parameters affect the model\n",
    "- Practice with real datasets\n",
    "- Evaluate model performance\n",
    "\n",
    "## ğŸ“– Table of Contents\n",
    "\n",
    "1. [What is Linear Regression?](#section1)\n",
    "2. [Mathematical Foundation](#section2)\n",
    "3. [Simple Linear Regression - Interactive Demo](#section3)\n",
    "4. [Predict Exam Score with the model we built](#section4)\n",
    "5. [Multiple Linear Regression](#section5)\n",
    "6. [Model Evaluation](#section6)\n",
    "7. [Practice Exercises](#section7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "## 1. ğŸ¤” What is Linear Regression?\n",
    "\n",
    "> **Oneâ€‘line intuition:** *Linear regression draws the simplest possible trendâ€‘line through your data by **adding up weighted pieces of the input**.*\n",
    "\n",
    "### Formal Definition\n",
    "\n",
    "Linear regression models the relationship between a **target** (dependent variable, $y$) and one or more **features** (independent variables, collected in a design matrix $X$) by learning coefficients $\\boldsymbol{\\beta}$ that appear **linearly** in the equation\n",
    "\n",
    "$$\n",
    "\\hat y = \\beta_0 + \\beta_1\\,f_1(X)\\; + \\; \\beta_2\\,f_2(X)\\; + \\;\\dots + \\beta_k\\,f_k(X).\n",
    "$$\n",
    "\n",
    "The functions $f_j(\\cdot)$ may be nonlinear transformations of the raw inputs (e.g. $X^2$, $\\log X$), yet the *parameters* $\\beta_j$ enter only as *additive, firstâ€‘power* termsâ€”this is what keeps the model \"linear\".\n",
    "\n",
    "### ğŸ¤“ Why â€œLinear in Parametersâ€ Matters\n",
    "\n",
    "* **ğŸ“ Straight line**: $Y=\\beta_0+\\beta_1X$\n",
    "* **ğŸŒ€ Curved but linear**: $Y=\\beta_0+\\beta_1X+\\beta_2X^2$\n",
    "* **ğŸ“‰ Log transform**: $Y=\\beta_0+\\beta_1\\log X$\n",
    "* **ğŸ”— Interaction**: $Y=\\beta_0+\\beta_1X_1+\\beta_2X_2X_3$\n",
    "\n",
    "If a coefficient is *wrapped inside* a nonlinear functionâ€”e.g. $Y = \\beta_0 + e^{\\beta_1 X}$â€”the model leaves the linearâ€‘regression family and becomes genuinely *nonlinear*.\n",
    "\n",
    "## ğŸ“˜ Key Concepts\n",
    "\n",
    "**Dependent variable (Y)**: What we want to predict\n",
    "\n",
    "**Independent variables (X)**: What we use to make predictions\n",
    "\n",
    "**Weights / Coefficients ($\\beta$)**: Learned parameters that quantify each feature's influence\n",
    "\n",
    "**Model linearity**: Linear in parametersâ€”even if relationship appears curved\n",
    "\n",
    "**Design matrix (X)**: Matrix containing all input features plus intercept column\n",
    "\n",
    "**Residuals ($\\varepsilon$)**: Differences between actual and predicted values\n",
    "\n",
    "### When to Reach for Linear Regression\n",
    "\n",
    "* You believe the (possibly transformed) features relate approximately linearly to the target.\n",
    "* You need an **interpretable** baseline before trying fancier models.\n",
    "* The target is **continuous** and errors are roughly symmetrical.\n",
    "* You want a quick yardâ€‘stick: linear models train instantly and provide a benchmark for MSE / $R^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id='section2'></a>\n",
    "\n",
    "## 2. ğŸ§® Mathematical Foundation\n",
    "\n",
    "### 2.1  Model in Vector / Matrix Form\n",
    "\n",
    "Given\n",
    "\n",
    "* Design matrix $X\\in\\mathbb{R}^{n\\times (k+1)}$ (first columnÂ =Â 1â€™s for the intercept)\n",
    "* Parameter vector $\\boldsymbol{\\beta}\\in\\mathbb{R}^{k+1}$\n",
    "* Target vector $\\mathbf{y}\\in\\mathbb{R}^{n}$\n",
    "\n",
    "we write\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}} = X\\,\\boldsymbol{\\beta}, \\qquad \\mathbf{y}=\\hat{\\mathbf{y}}+\\boldsymbol{\\varepsilon}.\n",
    "$$\n",
    "\n",
    "### 2.2  Objective Function (Ordinary Least Squares)\n",
    "\n",
    "The coefficients are chosen to **minimise** the Mean Squared Error (MSE):\n",
    "\n",
    "$$\n",
    "J(\\boldsymbol{\\beta})\n",
    "= \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat y_i)^2\n",
    "= \\frac{1}{n}\\lVert\\mathbf{y}-X\\boldsymbol{\\beta}\\rVert_2^{\\,2}.\n",
    "$$\n",
    "\n",
    "### 2.3  Closedâ€‘form Solution (Normal Equation)\n",
    "\n",
    "When $X^TX$ is invertible,\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}\\;=\\;(X^T X)^{-1}X^T\\mathbf{y}.\n",
    "$$\n",
    "\n",
    "This gives the exact OLS solution in a single matrix step.\n",
    "\n",
    "### 2.4  Gradientâ€‘descent Alternative\n",
    "\n",
    "For huge datasets or streaming contexts we iterate\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\beta}\\leftarrow\\boldsymbol{\\beta} - \\eta \\frac{2}{n} X^T(X\\boldsymbol{\\beta}-\\mathbf{y}),\n",
    "$$\n",
    "\n",
    "with learningâ€‘rate $\\eta$.\n",
    "\n",
    "### 2.5  Quality Metrics\n",
    "\n",
    "| ğŸ“ Metric | ğŸ“ Formula                                    | ğŸ“£ Meaning         |\n",
    "| --------- | --------------------------------------------- | ------------------ |\n",
    "| ğŸ¯ $R^2$  | $1-\\frac{\\sum(y-\\hat y)^2}{\\sum(y-\\bar y)^2}$ | Variance explained |\n",
    "| ğŸ§® MSE    | $\\frac{1}{n}\\sum(y-\\hat y)^2$                 | Avg. squared error |\n",
    "| ğŸ“‰ MAE    | $\\frac{1}{n}\\sum\\|y-\\hat y\\|$                 | Avg. absolute error |\n",
    "\n",
    "### 2.6  Classical Assumptions (OLS)\n",
    "\n",
    "1. **Linearity** in parameters\n",
    "2. **Independence** of errors\n",
    "3. **Homoscedasticity** (constant error variance)\n",
    "4. **No perfect multicollinearity** among features\n",
    "5. **Normality** of errors (for inference)\n",
    "\n",
    "Violating these does *not* break prediction, but it affects reliability of confidence intervals and hypothesis tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "## 3. ğŸ® Simple Linear Regression - Interactive Demo\n",
    "\n",
    "Time to get hands-on! We'll use a dataset of **student study hours** and **exam scores** to understand how linear regression works.\n",
    "\n",
    "### ğŸ¯ Your Mission\n",
    "Use the interactive sliders below to find the **best-fitting line** through the data points. Minimize the **Mean Squared Error (MSE)** by adjusting:\n",
    "\n",
    "- **Slope (Î²â‚)**: How much exam score increases per study hour\n",
    "- **Intercept (Î²â‚€)**: Baseline score when study hours = 0\n",
    "\n",
    "### ğŸ® Interactive Challenge\n",
    "**Move the sliders below** and watch the line change! Try to:\n",
    "1. **Minimize MSE** (lower is better)\n",
    "2. **Maximize RÂ²** (closer to 1.0 is better)\n",
    "3. **Center the line** through the data points\n",
    "\n",
    "**ğŸ’¡ Pro tip**: The best line minimizes squared distances from all points!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas matplotlib seaborn scikit-learn ipywidgets plotly\n",
    "!wget https://raw.githubusercontent.com/Khayrulbuet13/Medium-Posts/refs/heads/main/LinnearRegression/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Welcome to the Interactive Linear Regression Learning Playbook!\n",
      "ğŸš€ All libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()      # â† enable 3rd-party widgets\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"colab\"            # â† make sure Plotly targets Colab\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Import our utility functions\n",
    "import utils\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ“š Welcome to the Interactive Linear Regression Learning Playbook!\")\n",
    "print(\"ğŸš€ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple student scores dataset saved successfully to simple_student_scores.csv!\n",
      "Student scores dataset saved successfully to student_scores.csv!\n",
      "Simple house price dataset saved successfully to simple_house_price_dataset.csv!\n",
      "House price dataset saved successfully to house_price_dataset.csv!\n",
      "All csv files created successfully!\n"
     ]
    }
   ],
   "source": [
    "utils.create_simple_student_score_dataset(), utils.create_student_score_dataset()\n",
    "utils.create_simple_house_price_dataset(), utils.create_house_price_dataset()\n",
    "print(\"All csv files created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cc14d1d1554caab75413f3b90d4a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1 style=\"text-align: center; font-family: Arial, sans-serif; color: #2c3e50; margâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('simple_student_scores.csv')\n",
    "\n",
    "# Create an interactive regression demo using only Study_Hours as input\n",
    "slope_slider, intercept_slider = utils.create_interactive_regression_demo(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the optimal solution looks like\n",
    "X_demo = df['Study_Hours'].values\n",
    "y_demo = df['Exam_Score'].values\n",
    "\n",
    "# Implement find_optimal_parameters directly here\n",
    "X_reshaped = X_demo.reshape(-1, 1)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_reshaped, y_demo)\n",
    "\n",
    "optimal_slope = model.coef_[0] if X_demo.ndim == 1 else model.coef_\n",
    "optimal_intercept = model.intercept_\n",
    "y_pred_optimal = model.predict(X_reshaped)\n",
    "optimal_mse = mean_squared_error(y_demo, y_pred_optimal)\n",
    "optimal_r2 = r2_score(y_demo, y_pred_optimal)\n",
    "\n",
    "print(\"ğŸ¯ OPTIMAL SOLUTION (using sklearn):\")\n",
    "print(f\"   Optimal Slope: {optimal_slope:.3f}\")\n",
    "print(f\"   Optimal Intercept: {optimal_intercept:.3f}\")\n",
    "print(f\"   Minimum MSE: {optimal_mse:.3f}\")\n",
    "print(f\"   RÂ² Score: {optimal_r2:.3f}\")\n",
    "print(\"\\nğŸ’¡ How close were you to the optimal solution?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "## 4. ğŸ“Š Predict Exam Score with the model we built\n",
    "You can hover over the interactive window to see what should be the exam score from given study hours, or we can use the linear regression model we just built to predict the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Study_hours = [1, 3, 5, 7, 9]\n",
    "# Example predictions\n",
    "print(f\"\\nğŸ“Š Example Predictions:\")\n",
    "for hours in Study_hours:\n",
    "             score = model.predict([[hours]])[0]\n",
    "             print(f\"   {hours} hours â†’ {score:.1f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "\n",
    "## 5. ğŸ”¢ Multiple Linear Regression\n",
    "\n",
    "Now let's explore multiple linear regression with more features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the multiple linear regression dataset from CSV\n",
    "df_multi = pd.read_csv('student_scores.csv')\n",
    "\n",
    "print(\"ğŸ“Š Multiple Linear Regression Dataset\")\n",
    "print(f\"Dataset shape: {df_multi.shape}\")\n",
    "# print(\"\\nFirst 10 students:\")\n",
    "display(df_multi.head(10))\n",
    "\n",
    "print(\"\\nğŸ“ Description:\")\n",
    "print(\"This dataset contains simulated student data with the following features:\")\n",
    "print(\"- Study_Hours: Number of hours spent studying per week\")\n",
    "print(\"- Sleep_Hours: Average hours of sleep per night\")\n",
    "print(\"- Previous_Score: Previous exam score (out of 100)\")\n",
    "print(\"- Attendance_Percent: Class attendance percentage\")\n",
    "print(\"- Exam_Score: Current exam score (target variable, out of 100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multiple linear regression model\n",
    "X_multi = df_multi[['Study_Hours', 'Sleep_Hours', 'Previous_Score', 'Attendance_Percent']]\n",
    "y_multi = df_multi['Exam_Score']\n",
    "\n",
    "# Split the data\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train the model\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_multi = model_multi.predict(X_train_multi)\n",
    "y_test_pred_multi = model_multi.predict(X_test_multi)\n",
    "\n",
    "print(f\"ğŸ¯ Multiple Regression Model Parameters:\")\n",
    "feature_names = ['Study_Hours', 'Sleep_Hours', 'Previous_Score', 'Attendance_Percent']\n",
    "for i, (feature, coef) in enumerate(zip(feature_names, model_multi.coef_)):\n",
    "    print(f\"   {feature}: {coef:.3f}\")\n",
    "print(f\"   Intercept: {model_multi.intercept_:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Multiple Regression Performance:\")\n",
    "print(f\"   Training RÂ² Score: {r2_score(y_train_multi, y_train_pred_multi):.3f}\")\n",
    "print(f\"   Test RÂ² Score: {r2_score(y_test_multi, y_test_pred_multi):.3f}\")\n",
    "print(f\"   Training MSE: {mean_squared_error(y_train_multi, y_train_pred_multi):.3f}\")\n",
    "print(f\"   Test MSE: {mean_squared_error(y_test_multi, y_test_pred_multi):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§® How Multiple Regression Predicts Exam Scores\n",
    "\n",
    "A **multiple linear regression** model predicts the target using this equation:\n",
    "\n",
    "### Multiple Linear Regression:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_4x_4 + \\epsilon$$\n",
    "\n",
    "Where:\n",
    "- $y$ = Exam Score (what we predict)\n",
    "- $\\beta_0$ = Intercept (baseline score)\n",
    "- $\\beta_1, \\beta_2, \\beta_3, \\beta_4$ = Coefficients for each feature\n",
    "- $x_1, x_2, x_3, x_4$ = Study Hours, Sleep Hours, Previous Score, Attendance\n",
    "- $\\epsilon$ = Error term\n",
    "\n",
    "**Example prediction with your model:**\n",
    "\n",
    "$$\\text{Exam Score} = 51.191 + 3.438 \\times \\text{Study Hours} + 0.848 \\times \\text{Sleep Hours} + 0.122 \\times \\text{Previous Score} + 0.102 \\times \\text{Attendance}$$\n",
    "\n",
    "### Cost Function (Mean Squared Error):\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "The goal is to find the best coefficients that **minimize** this cost function!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "\n",
    "## 6. ğŸ“ Model Evaluation\n",
    "\n",
    "Understanding how to evaluate your linear regression model is crucial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model evaluation using our utility function\n",
    "# Make predictions\n",
    "y_pred = model_multi.predict(X_test_multi)\n",
    "\n",
    "# Calculate various metrics\n",
    "r2 = r2_score(y_test_multi, y_pred)\n",
    "mse = mean_squared_error(y_test_multi, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_multi, y_pred)\n",
    "\n",
    "# Additional metrics\n",
    "n = len(y_test_multi)\n",
    "p = X_test_multi.shape[1]  # number of features\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# Mean and standard deviation of residuals\n",
    "residuals = y_test_multi - y_pred\n",
    "residual_mean = np.mean(residuals)\n",
    "residual_std = np.std(residuals)\n",
    "\n",
    "print(\"ğŸ“Š COMPREHENSIVE MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nğŸ¯ Accuracy Metrics:\")\n",
    "print(f\"   RÂ² Score: {r2:.4f}\")\n",
    "print(f\"   Adjusted RÂ²: {adjusted_r2:.4f}\")\n",
    "print(f\"   Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"   Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"   Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ” Residual Analysis:\")\n",
    "print(f\"   Residual Mean: {residual_mean:.4f} (should be close to 0)\")\n",
    "print(f\"   Residual Std Dev: {residual_std:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Interpretation:\")\n",
    "print(f\"   â€¢ RÂ² = {r2:.3f} means {r2*100:.1f}% of variance is explained\")\n",
    "print(f\"   â€¢ On average, predictions are off by {mae:.1f} points (MAE)\")\n",
    "print(f\"   â€¢ RMSE of {rmse:.1f} penalizes larger errors more than MAE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "\n",
    "## ğŸ  Exercise 1: House Price Prediction Challenge\n",
    "\n",
    "Build a simple linear regression model to predict house prices and discover key factors that influence property values!\n",
    "\n",
    "### ğŸ“Š The Dataset\n",
    "\n",
    "The `simple_house_price_dataset.csv` dataset contains:\n",
    "- **Size_SqFt**: House size in square feet\n",
    "- **Location_Score**: Location quality (1-10 scale)\n",
    "- **Age_Years**: Age of the house\n",
    "- **Price_USD**: House price (target variable)\n",
    "\n",
    "### ğŸ¯ Your Mission\n",
    "\n",
    "Create a model that predicts house prices by:\n",
    "1. **Exploring** the data with quick statistics and visualizations\n",
    "2. **Building** a multiple linear regression model\n",
    "3. **Evaluating** performance with RÂ² and MSE\n",
    "4. **Interpreting** which factors impact price most\n",
    "5. **Predicting** prices for sample properties\n",
    "\n",
    "### ğŸ“ Steps to Complete\n",
    "\n",
    "1. **Explore**: Check statistics and correlations\n",
    "2. **Visualize**: Create scatter plots\n",
    "3. **Build**: Use multiple linear regression\n",
    "4. **Evaluate**: Calculate RÂ², MSE metrics\n",
    "5. **Interpret**: Analyze coefficients\n",
    "6. **Predict**: Test on sample houses\n",
    "\n",
    "Ready to become a real estate pricing expert? ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ  Exercise 1 - Predicting House Prices\n",
    "\n",
    "# ğŸš€ Goal: Build a multiple linear regression model to predict house prices based on key features.\n",
    "\n",
    "# STEP 1ï¸âƒ£: Load and preview the dataset\n",
    "# Dataset: simple_house_price_dataset.csv\n",
    "# Contains: Size_SqFt, Location_Score, Age_Years, Price_USD\n",
    "# Hint: Use pd.read_csv() and display(df.head())\n",
    "# df_houses = ...\n",
    "# display(df_houses.head())\n",
    "\n",
    "# STEP 2ï¸âƒ£: Explore the data\n",
    "# Print basic statistics and check for missing values\n",
    "# df_houses.describe()\n",
    "# df_houses.info()\n",
    "\n",
    "# STEP 3ï¸âƒ£: Visualize relationships\n",
    "# Use scatterplots to examine correlation between each feature and the house price\n",
    "# Example: sns.scatterplot(x='Size_SqFt', y='Price_USD', data=df_houses)\n",
    "\n",
    "# STEP 4ï¸âƒ£: Define features (X) and target (y)\n",
    "# Features: Size_SqFt, Location_Score, Age_Years\n",
    "# Target: Price_USD\n",
    "# X = df_houses[[...]]\n",
    "# y = df_houses['Price_USD']\n",
    "\n",
    "# STEP 5ï¸âƒ£: Split data into training and testing sets\n",
    "# Use test_size=0.2 and random_state=42 for reproducibility\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# STEP 6ï¸âƒ£: Train the linear regression model\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 7ï¸âƒ£: Evaluate model performance\n",
    "# Use r2_score and mean_squared_error\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(\"RÂ² Score:\", ...)\n",
    "# print(\"MSE:\", ...)\n",
    "\n",
    "# STEP 8ï¸âƒ£: Predict prices for sample properties\n",
    "# Try a property with: 1800 sq ft, location score 7, age 10 years\n",
    "# new_house = pd.DataFrame([{...}])\n",
    "# predicted_price = model.predict(new_house)\n",
    "# print(\"Predicted Price (USD):\", predicted_price[0])\n",
    "\n",
    "# ğŸ” Optional: Visualize actual vs predicted prices\n",
    "# Use a scatterplot or line plot to show model performance visually\n",
    "\n",
    "# âœï¸ Your code here:\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ  Exercise 2: Advanced Feature Engineering\n",
    "\n",
    "Take your house price model to the next level by applying feature engineering techniques to improve prediction accuracy!\n",
    "\n",
    "### ğŸ“Š Enhanced Features\n",
    "\n",
    "Building on Exercise 1, explore additional features:\n",
    "- **Ceiling_Height_Ft**: Ceiling height in feet\n",
    "- **Garage_Size_Cars**: Garage capacity\n",
    "- **Distance_to_Metro_km**: Distance to nearest metro station\n",
    "\n",
    "### ğŸ”§ Engineering Techniques\n",
    "\n",
    "Try these transformations to boost model performance:\n",
    "- **Polynomial features**: `Size_SqFtÂ²`, `Age_YearsÂ³`\n",
    "- **Logarithmic features**: `log(Size_SqFt)`, `log(Distance_to_Metro_km + 1)`\n",
    "- **Interaction terms**: `Size_SqFt Ã— Location_Score`\n",
    "\n",
    "### ğŸ“ˆ Your Challenge\n",
    "\n",
    "1. Compare basic vs. engineered models\n",
    "2. Identify which features contribute most\n",
    "3. Visualize how feature engineering improves predictions\n",
    "\n",
    "Can you create a model that outperforms your Exercise 1 solution? ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ  Exercise 2 - Advanced Feature Engineering for House Price Prediction\n",
    "\n",
    "# ğŸš€ Goal: Improve model accuracy using new features and transformations\n",
    "\n",
    "# STEP 1ï¸âƒ£: Load and preview the dataset\n",
    "# Uncomment the line below to check the structure of your data\n",
    "# df_houses = pd.read_csv('house_price_dataset.csv')\n",
    "# display(df_houses.head())\n",
    "\n",
    "# STEP 2ï¸âƒ£: Review new features\n",
    "# Make sure your dataset includes the following columns:\n",
    "# - Size_SqFt\n",
    "# - Location_Score\n",
    "# - Age_Years\n",
    "# - Ceiling_Height_Ft\n",
    "# - Garage_Size_Cars\n",
    "# - Distance_to_Metro_km\n",
    "# - Price_USD (target)\n",
    "\n",
    "# Print summary statistics and check for missing values\n",
    "# print(df_houses.describe())\n",
    "# print(df_houses.isnull().sum())\n",
    "\n",
    "# STEP 3ï¸âƒ£: Engineer new features\n",
    "# Apply transformations such as:\n",
    "# - Polynomial terms: e.g., Size_SqFtÂ², Age_YearsÂ³\n",
    "# - Logarithmic transforms: e.g., log(Size_SqFt), log(Distance_to_Metro_km + 1)\n",
    "# - Interaction terms: Size_SqFt Ã— Location_Score\n",
    "\n",
    "# Example:\n",
    "# df_houses['Size_SqFt_Squared'] = df_houses['Size_SqFt'] ** 2\n",
    "# df_houses['Log_Size_SqFt'] = np.log(df_houses['Size_SqFt'] + 1)\n",
    "# df_houses['Size_Location_Interaction'] = df_houses['Size_SqFt'] * df_houses['Location_Score']\n",
    "\n",
    "# STEP 4ï¸âƒ£: Define features and target\n",
    "# Choose a mix of original + engineered features\n",
    "# X = df_houses[['Size_SqFt', 'Ceiling_Height_Ft', 'Garage_Size_Cars', ...]]\n",
    "# y = df_houses['Price_USD']\n",
    "\n",
    "# STEP 5ï¸âƒ£: Train-test split and model fitting\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# model = LinearRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 6ï¸âƒ£: Evaluate model performance\n",
    "# Use RÂ², MSE, and RMSE to compare against the base model\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(\"RÂ²:\", ...)\n",
    "# print(\"MSE:\", ...)\n",
    "# print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# STEP 7ï¸âƒ£: Visualize predictions\n",
    "# Plot actual vs predicted prices using matplotlib or seaborn\n",
    "# sns.scatterplot(x=y_test, y=y_pred)\n",
    "# plt.xlabel(\"Actual Price\")\n",
    "# plt.ylabel(\"Predicted Price\")\n",
    "\n",
    "# STEP 8ï¸âƒ£: Reflect â€” did feature engineering help?\n",
    "# Which features appear most influential (use model.coef_ or SHAP if you wish)\n",
    "\n",
    "# âœï¸ Your code here:\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You've completed the Interactive Linear Regression Learning Playbook! Here's what you've learned:\n",
    "\n",
    "### ğŸ“š Key Takeaways:\n",
    "1. **Linear Regression Fundamentals**: Understanding the mathematical foundation and when to use it\n",
    "2. **Interactive Learning**: How adjusting parameters affects model performance\n",
    "3. **Real-world Application**: Working with student scores dataset\n",
    "4. **Multiple Features**: Extending to multiple linear regression\n",
    "5. **Model Evaluation**: Comprehensive metrics and interpretation\n",
    "6. **Hands-on Practice**: Building your own models\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "- Try the practice exercises with different datasets\n",
    "- Experiment with feature engineering\n",
    "- Explore regularization techniques (Ridge, Lasso)\n",
    "- Learn about polynomial regression\n",
    "- Study advanced regression techniques\n",
    "\n",
    "### ğŸ“– Additional Resources:\n",
    "\n",
    "- **[Scikit-learn Linear Regression Documentation](https://scikit-learn.org/stable/modules/linear_model.html)**  \n",
    "  Authoritative reference for implementing and tuning linear regression in Python.\n",
    "\n",
    "- **[StatQuest: Linear Models (YouTube)](https://www.youtube.com/watch?v=nk2CQITm_eo)**  \n",
    "  Clear, friendly walkthrough of the math behind linear regression. Highly recommended for beginners.\n",
    "\n",
    "- **[An Introduction to Statistical Learning (ISLR) â€“ Free PDF](https://www.statlearning.com/)**  \n",
    "  Chapter 3 covers linear regression clearly with R/Python examples and hands-on insights.\n",
    "\n",
    "Happy learning! ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
